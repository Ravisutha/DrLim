{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Dr LIM - Dimensionality reduction by Learning Invariant Mapping\n",
    "\n",
    "- This paper (similar to TSNE) proposes an alternative method to achieve dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from image_utilities import plot_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## CNN used in the paper \n",
    "\n",
    "![CNN architecture](./images/cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Torch implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DrlimCNN(\n",
       "  (layer_1): Conv2d(1, 15, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (max_pooling): MaxPool2d(kernel_size=15, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer_3): Conv2d(15, 30, kernel_size=(10, 10), stride=(1, 1))\n",
       "  (output_layer): Linear(in_features=30, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DrlimCNN(nn.Module):\n",
    "    def __init__(self, n_lower_dim=2):\n",
    "        super(DrlimCNN, self).__init__()\n",
    "        \n",
    "        # Layer 1:\n",
    "        # n_input_channel = 1\n",
    "        # n_output_channel = 15\n",
    "        # Kernel Size = 5 for padding = 0, stride = 1\n",
    "        k_size = 5\n",
    "        in_channels = 1\n",
    "        out_channels = 15 \n",
    "        self.layer_1 = nn.Conv2d(in_channels, out_channels, k_size)\n",
    "        \n",
    "        # Layer 2: Subsampling - Maxpooling\n",
    "        # Kernel Size = 15  for padding=0 and stride = 1\n",
    "        k_size = 15\n",
    "        self.max_pooling = nn.MaxPool2d(k_size, stride=1)\n",
    "        \n",
    "        # Layer 3: Conv layer\n",
    "        # n_input_channel = 15\n",
    "        # n_output_channel = 30\n",
    "        # Kernel size = 10\n",
    "        in_channels = 15\n",
    "        out_channels = 30\n",
    "        k_size = 10\n",
    "        self.layer_3 = nn.Conv2d(in_channels, out_channels, k_size)\n",
    "        \n",
    "        # Layer 4: Fully connected\n",
    "        self.output_layer = nn.Linear(30, n_lower_dim)\n",
    "        \n",
    "        # Relu\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add relu on top of conv layer\n",
    "        x = self.layer_1(x)\n",
    "        #x = self.relu(x)\n",
    "        \n",
    "        # Maxpool \n",
    "        x = self.max_pooling(x)\n",
    "        \n",
    "        # Another conv\n",
    "        x = self.layer_3(x)\n",
    "        \n",
    "        # Get the size except for batch\n",
    "        num_flat_features = reduce(lambda x, y: x * y, x.shape[1:])\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.reshape(-1, num_flat_features)\n",
    "        \n",
    "        # Fully connected \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "net = DrlimCNN()\n",
    "\n",
    "# Enable GPU\n",
    "net.to(device)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Define contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(output_1, output_2, \n",
    "            target_1, target_2):\n",
    "    \n",
    "    # TODO:\n",
    "    #    if target_1 == target_2:\n",
    "    #        y = torch.zeros_like(output_1, requires_grad=True)\n",
    "    #    else:\n",
    "    #        y = torch.ones_like(output_1, requires_grad=True)\n",
    "        \n",
    "    y = 1 - torch.eq(target_1, target_2).int()\n",
    "        \n",
    "    distance = torch.norm(output_1 - output_2, dim=1)\n",
    "    \n",
    "    # Similar loss\n",
    "    ls = torch.pow(distance, 2)\n",
    "    \n",
    "    # Dissimilar loss\n",
    "    m = 10\n",
    "    ld = torch.max(torch.zeros_like(distance), m - distance)\n",
    "    ld = torch.pow(ld, 2)\n",
    "    \n",
    "    loss = torch.mean((1 - y) * ls + y * ld)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = False \n",
    "if test:\n",
    "    # Test Code\n",
    "    input_1 = torch.randn(1, 1, 28, 28)\n",
    "    input_2 = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "    out_1 = net(input_1.cuda())\n",
    "    out_2 = net(input_2.cuda())\n",
    "    out_1 = out_1.requires_grad_(True)\n",
    "    out_2 = out_2.requires_grad_(True)\n",
    "\n",
    "    print(\"Before:\")\n",
    "    print(net.output_layer.weight.grad)\n",
    "    loss = contrastive_loss(out_1, out_2,\n",
    "                            0, 0)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    print(\"After:\")\n",
    "    print(net.output_layer.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,), (0.3081,))\n",
    "                               ])),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.001)\n",
    "\n",
    "all_data = []\n",
    "all_target = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    # Choose only either 5 or 10 number \n",
    "    filter_index = ((target == 4) | (target == 9))\n",
    "    all_data += data[filter_index].numpy().tolist()\n",
    "    all_target += target[filter_index].numpy().tolist()\n",
    "    \n",
    "all_data.pop()\n",
    "all_target.pop()\n",
    "batch_size = 30\n",
    "\n",
    "all_data = np.array(all_data).reshape(11790, 1, 28, 28)\n",
    "all_target = np.array(all_target).reshape(11790, 1)\n",
    "\n",
    "all_data = np.array(all_data).reshape(-1, 30, 28, 28)\n",
    "all_target = np.array(all_target).reshape(-1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 261] loss: 0.03707598549127579  \r"
     ]
    }
   ],
   "source": [
    "loss_cache = []\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(all_data): \n",
    "        target = torch.tensor(all_target[i], dtype=torch.float32)\n",
    "        data  = torch.tensor(data, dtype=torch.float32)\n",
    "        data = torch.unsqueeze(data, 1).to(device)\n",
    "        \n",
    "        input_data, label = data, target\n",
    "        \n",
    "        out = net(input_data)\n",
    "        out_1, label_1 = out[:15], target[:15]\n",
    "        out_2, label_2 = out[15:], target[15:]\n",
    "        loss = contrastive_loss(out_1.to('cpu'), out_2.to('cpu'),\n",
    "                                label_1, label_2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_cache.append(loss.detach())\n",
    "\n",
    "        out_1 = out_1.requires_grad_(True)\n",
    "        out_2 = out_2.requires_grad_(True)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 0:    # print every 2000 mini-batches\n",
    "            print('[{}, {}] loss: {} \\r'.format(epoch + 1, i + 1, running_loss / 2000), end=\"\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "print(\"\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(loss_cache))), loss_cache)\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,), (0.3081,))\n",
    "                               ])),\n",
    "    batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "data_4 = []\n",
    "target_4 = []\n",
    "\n",
    "data_11 = []\n",
    "target_11 = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # Choose only either 5 or 10 number \n",
    "    filter_index = (target == 4)\n",
    "    data_4 += data[filter_index].numpy().tolist()\n",
    "    target_4 += target[filter_index].numpy().tolist()\n",
    "    \n",
    "    filter_index = (target == 9)\n",
    "    data_11 += data[filter_index].numpy().tolist()\n",
    "    target_11 += target[filter_index].numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Manifold\n",
    "data_manifold_4 = [] \n",
    "data_manifold_11 = [] \n",
    "\n",
    "for i in range(len(data_4)):\n",
    "    input_4 = torch.tensor(data_4[i]).unsqueeze(0).to(device)\n",
    "    out = net(input_4)\n",
    "    out = out.clone()\n",
    "    out = out.cpu().detach().numpy().squeeze()\n",
    "    data_manifold_4.append(out)\n",
    "    \n",
    "data_manifold_4 = np.array(data_manifold_4)\n",
    "    \n",
    "for i in range(len(data_11)):\n",
    "    input_11 = torch.tensor(data_11[i]).unsqueeze(0).to(device)\n",
    "    out = net(input_11)\n",
    "    out = out.clone()\n",
    "    out = out.cpu().detach().numpy().squeeze()\n",
    "    data_manifold_11.append(out)\n",
    "    \n",
    "data_manifold_11 = np.array(data_manifold_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_11_x = data_manifold_11[:, 0]\n",
    "data_11_y = data_manifold_11[:, 1]\n",
    "\n",
    "data_4_x = data_manifold_4[:, 0]\n",
    "data_4_y = data_manifold_4[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_11_x, data_11_y, color=\"r\", label=\"Number 11\")\n",
    "plt.scatter(data_4_x, data_4_y, color=\"b\", label=\"Number 4\", alpha=0.1)\n",
    "plt.title(\"Lower dimensional map - Number 11 and Number 4\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
